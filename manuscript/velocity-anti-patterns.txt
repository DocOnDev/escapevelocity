# Velocity Anti-Patterns

If you've been on an agile team that uses velocity as a key metric, you've
probably experienced or at least witnessed some pretty strange behavior.

Ask a group of agile coaches about dysfunctions they've seen on teams related
to the use of velocity and you'll get plenty of responses that inspire
head shaking and hand wringing.

That's exactly what we did to come up with the following list. This is by no
means comprehensive, but it is a reasonable representation of the issues that
exist within organizations when it comes to metrics and management.

## Before we get started
I want to be crystal clear here: The Velocity Anti-Patterns listed here are not
necessarily indications from measuring and reporting velocity.
Many are indications of the pervasiveness of poor management.

You see, Velocity itself is not necessarily harmful.
It is a tool and nothing more.
Just as a knife is a tool and nothing more.
It is not until the human element is introduced that the tool becomes potentially dangerous.
Whether deliberate or inadvertent, it is interaction with the tool that introduces risk.
The better fit the tool is for purpose and the more deliberate and informed the individual,
the lower the risk.

So with that in mind, let's take a look at some of the most common Velocity
Anti-Patterns identified by our coaches and practitioners.

## Demand for Higher Velocity

This is far and away, the most common Velocity Anti-Pattern, and quite possibly
the most harmful.


## Cross-Team Velocity Comparisons
A common anti-pattern in a great deal of organizations is velocity comparison
across teams.

"Your velocity is 20 and theirs is 50. What are you doing wrong?", asks a
manager with good but misguided intentions.

"You cannot compare velocity across teams.", says the agile coach,
"Velocity measures are unique to each team."

"Surely, there will be some variance from team to team", the manager agrees,
"but a 2x difference must indicate trouble."

Of course, we rarely assume the team reporting a velocity of 50 is the team in
trouble.
More velocities are always better, right?

Let's dive into this one a bit.
Why is it that comparison of velocity across teams is deemed an anti-pattern?
How come we can't do this in an ideal environment?

The short answer is there are no ideal environments. But let's look closer.

There is a great deal of debate over how velocity is best calculated.
From story points to ideal days to hours.
From effort to complexity to duration to value.
From comparative to scalar to absolute.
From t-shirt sizes to fibonacci to linear.
Even when two teams in an organization agree on all of these factors,
calibration is still extremely difficult.
We're using metaphors to represent guesses about work items for which we've a
varying level of shared understanding and varying tolerances for risk.

Imagine this scenario; there are two hike teams given the same basic challenge.
"You are about to embark on a multi-day hike over territory none of you has
ever before covered in hopes of getting excellent photography.
It will be similar to other journeys you've taken, but subtly different in
an indeterminate number of ways.
Our map is incomplete in parts and the path we've identified is our best guess.
We've broken the hike into trail sections based on spots along the way that
we think will make great photo opportunities.
The terrain will vary significantly; some of it may be new to all but one or
two of you.
Some of it may be dissimilar to terrain any of you have ever seen.
With these factors in mind, please indicate the number of units involved in the
journey where a unit is a measure of energy expended in completing a section
of the trail.
Please indicate units on a fibonacci scale with no unit greater than 21."

Each team estimates based on these criteria and hike for an hour.
We measure the number of units each team completes in the first hour.
We can use this data to better estimate how long it will take them to complete
the entire journey.
As it works out, Team A completes 20 units in the first hour and Team B
completes 45 units in the first hour.

So here is the question - Which team is the better performer?

The truth is, we cannot know that from the data provided.
The teams may be similar, but they are not the same.
The paths may be similar, but they are not the same.
The skills and familiarity of the individuals may be similar, but they are not the same.
The accuracy of the maps may be similar, but they are not the same.
The navigability of the paths may be similar, but they are not the same.
The subjective assessment of anticipated energy expended that each team agrees on
will vary not only from team to team, but from session to session on the same
team.
There are many variables. Velocity (units per hour) is a course-grain estimate
unique to each team.

Hopefully, we can see that comparing such velocity across teams is an exercise
in frustration.

Now returning to software, the analogy holds fairly well.
The teams

One common solution to this "problem" is to have a core set of individuals do
all of the estimates.
The thinking being that consistency in the estimation makes execution comparable.







### All Estimates are Equal
comparing velocity across teams and asking everyone to get to a “similar” set of numbers

## Estimating in Time
Using days as points.
tying estimates to time.
If you mean scrum, using hours as points.

## Plan by Velocity over Value
Divorcing points from value and/or risk.
Focusing on velocity instead of value.

## Demand for Higher Velocity
Changing points so you can have higher velocity
rewarding teams for increased velocity
story point bloating because more is better.
"you need to increase velocity x% or else miss the deadline"


"We can't use points because of the process of having to give effort estimates for funding" PO straight out of PO Training. LoL

## Setting Velocity Goals
velocity targets
"you need to increase velocity x% or else miss the deadline"

## Rewards for Velocity
"Every developer must complete at least 13 points per sprint"
"Developers who complete an average of 13 story points will receive a Meets Expectations on their performance review"
"Developers who completes an average of 18 story points will receive a Exceeds Expectations on their performance review"


## Measuring Individual Velocity



"you can not add any points to the backlog once funding is approved"
measure team perf
forecasting neglecting variance
incl partially done work
partially estimated sprints
1) An organization holding multiple unrelated teams (diff domains and stacks) to the same standard of expected velocity per sprint
2) A Dev mgr reading team's old burndowns like tea leaves to tell them what they did wrong rather than interacting with the team
3) A coach telling a new scrum master "his team should have a velocity of 25" wh knowing nothing about the team, org, product
many SM and coaches not groking the proper Velocity Calculus
choosing between stories based on what fits within sprint rather than what's most important
having a team commit to a velocity number very early in a project (e.g. after 1 sprint)
having a long velocity history with documented team changes but never using it to forecast outcomes, giving made-up dates anyway.
point currency inflation on longer projects. Team member changes without expectation of velocity loss. Small sizing for deadline
Story points are assigned by the Product Owner.
Velocity-centric agile teams that eventually forget customer value and grow technical debt
playing story-point tetris to "fill" the sprint, throwing priorities out of the window
points as effort instead of complexity

Equating it with performance and setting a target: "You need to deliver 70 points this sprint."


Debating far too long about whether a story is 3 or 5 points.

Estimating components of a story (like development and test) and adding the two together. "It's a 5 to develop and a 2 to test, so it's a 7."

Hearing from a PM that, after a few iterations, a team "needs to get their velocity up" to ship everything on the planned date.

Seeing an "ideal" line on a burn-up/down chart annotated with the proper velocity.

fellow who was fond of reminding everyone within his domain he was entitled "Director of Engineering Practices and Services" explained to me "In agile a manager's job is to know his team's velocity and to make it go up."

> mgmt not understanding purpose of Velocity empirical measure;
> teams using some bogus statistical manipulation called an average without the understanding of the constrains that an average is valid within;
> SM allowing teams to carry over stories and get credit for multiple sprints within one measurement (lack of understanding of empirical);
> pressure to give "credit" for effort but zero results - culture dynamic viscous feedback loop;
> lack of understanding of the virtuous cycle that can be built with empirical measurement and understanding of trends;
> no action to embrace the virtuous benefits of a measure-respond-adapt model (specifically story slicing to appropriate size)

> breaking the basic tenants of the scrum estimation model - allow me to expand for those who have already condemned me for violating written (or suggesting unwritten) dogma...
a PBL item has a "size" before being Ready (a gate action) for planning;
the team adjusts the PBL item size any/ever time they touch the item and learn more about it (like at planning/grooming);
each item is sized based on effort/etc. from NOW (or start of sprint - a point in time) to DONE (never on past sunk cost effort);
empirical evidence and updated estimates are a good way to plan;

therefore carryover stories are resized before being brought into the next sprint - also reprioritized - and crying over spilt milk or lost effort credit is not allowed in baseball (or sprint planning)

The team wanting definition of done to be "code complete" instead of "deployed" so the burn down charts would look less depressing. Also, using burndown charts without actually having a strong sprint commitment from the team.
