## Delivery Frequency

{icon=quote-left}
G> “If it hurts, do it more frequently, and bring the pain forward.”
― Jez Humble, Continuous Delivery: Reliable Software Releases Through Build, Test, and Deployment Automation

Delivery frequency is a measurement of how often we release software.
When we combine it with things like escaped defects, we can see if releasing
more or less frequently nets more or less defects.

In studies done on the impact of automated deployment processes and the use
of version control for infrastructure management, Jez Humble and Gene Kim found
"that high performing organizations ship code 30 times faster (and complete
these deployments 8,000 times faster), have 50% fewer failed deployments,
and restore service 12 times faster than their peers."[^StateOfDevOps2014]

The more frequently a team releases, the more truly efficient their processes
need to be.
Teams that release with high frequency have driven waste out of their environments
in order to be able to do so.
Formalized phases of integration and acceptance and regression testing are folded
into the day to day process.

The rate of delivery is an indication of efficiency as the process needs to be
optimized to safely deploy often.
The rate of delivery is an indication of flexibility as it suggests the code
changes are small and incremental.

While delivery frequency suggests these things, it does not guarantee it.
I've seen many an environment where the team does minimal automated testing and
takes pride in their ability to deliver often.
I've seen numerous environments where delivery frequency includes patches and
bug fixes.
The teams are actually delivering new features at a slow pace, but are regularly
putting out fires.
I've had more than one release engineer explain the value of a fully automated
deployment pipeline despite a lack of testing and other rigor;
failing to realize how this might actually be contributing to the problem.

When looking at delivery frequency, consider it a team metric, not a departmental
metric.
What I mean by that is make sure to measure delivery frequency for each team.
How often the department releases may not give a clear depiction of how teams
are doing.
A department of 3 teams may release 20 times per day on average.
Look a little closer and you may find that one of the teams is releasing 19.7 times
per day on average, one releases every day or two, and one has not released
in several weeks.

Let's take a look at two departments, both of which are comprised of 10 teams and release 5 times per day.

{title="Department A", width="60%"}
|Team            |Releases Per Week |
|----------------|------------------|
|A               |2                 |
|B               |3.25              |
|C               |2                 |
|D               |3.5               |
|E               |2.25              |
|F               |3                 |
|G               |2.25              |
|H               |2.25              |
|I               |2.5               |
|J               |2                 |

{title="Department B", width="60%"}
|Team            |Releases Per Week |
|----------------|------------------|
|K               |1
|L               |2
|M               |1
|N               |5.25
|O               |2.25
|P               |7.25
|Q               |2.25
|R               |1.5
|S               |1.5
|T               |1

Both Departments release a total of 25 times per week on average.
This might lead us to believe that teams are releasing 2.5 times per week and that
the departments are similar in performance.

But if we look at the ranges for the values that comprise the mean, we see something telling.
The range for Department A is 1.5, whereas the range for Department B is 6.25.
For department A, no team is more than 1 release per week away from the average.
For department B, some of the teams are off average by as many as 4.75 releases per week.

The average delivery is the same for both departments, but it turns out that department B has not only the highest performing teams, but also the lowest. If we looked at only the rate for the department, we wouldn't see this difference.

By including the range, we can identify departments with outliers and drill in to get more insight.


### Frequency of Features, not Patches

Make sure frequency of release is a measure of features, not patches.
Certainly, the ability to deploy patches rapidly is a benefit, but it should not be the focus.
The goal is for each team to be able to deliver actual value to the customer in
the form of defect free features and functions.

Now, I am assuming support teams don't exist or that the support team is a triage team and the actual product team is responsible for break/fix.
If, on the other hand, you are segmented into teams that write software and teams that fix broken software written by others, then the rate at which your break/fix team can deploy patches is a reasonable measure.

#### Also, No Break/Fix Teams

I'm going to say this as straight as possible.

You shouldn't have a break/fix team.

If you have one (or many), restructure the teams so that the people that write the software are directly responsible for supporting it.
Overall solution quality is reduced whenever you have some teams responsible for writing software and some teams responsible for fixing it.

By folding this responsibility back into the delivery teams, you allow them to learn more rapidly and encourage them to double-check requirements and quality.
Break/fix teams encourage a lower quality product and impede learning from happening where it is most valuable.


[^StateOfDevOps2014]: 2014 State of DevOps Report. (n.d.). Retrieved June 29, 2017, from https://puppet.com/resources/whitepaper/2014-state-devops-report
